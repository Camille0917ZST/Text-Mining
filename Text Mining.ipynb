{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1.txt</td>\n",
       "      <td>there is a good wikipedia article on this.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a10.txt</td>\n",
       "      <td>there is no cure for gout but it can be treate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a100.txt</td>\n",
       "      <td>Laboratory rats whose diets are supplemented w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a101.txt</td>\n",
       "      <td>Heres a simple set of exercises that I do dail...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a102.txt</td>\n",
       "      <td>How to restore 20/20 vision.\\n\\nExercise 1:  \\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       file                                               text  class\n",
       "0    a1.txt        there is a good wikipedia article on this.       0\n",
       "1   a10.txt  there is no cure for gout but it can be treate...      0\n",
       "2  a100.txt  Laboratory rats whose diets are supplemented w...      0\n",
       "3  a101.txt  Heres a simple set of exercises that I do dail...      0\n",
       "4  a102.txt  How to restore 20/20 vision.\\n\\nExercise 1:  \\...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "def data2df (path, label):\n",
    "    file, text = [], []\n",
    "    for f in os.listdir(path):\n",
    "        file.append(f)\n",
    "        fhr = open(path+f, 'r', encoding=\"utf8\", errors='ignore') \n",
    "        t = fhr.read()\n",
    "        text.append(t)\n",
    "        fhr.close()\n",
    "    return(pd.DataFrame({'file': file, 'text': text, 'class':label}))\n",
    "\n",
    "dfnonpro = data2df('C:/Users/zengs/OneDrive/Desktop/Grad Term 2/CIS 509/Assignment 5/HealthProNonPro/NonPro/', 0) \n",
    "dfpro = data2df('C:/Users/zengs/OneDrive/Desktop/Grad Term 2/CIS 509/Assignment 5/HealthProNonPro/Pro/', 1) \n",
    "\n",
    "df = pd.concat([dfnonpro, dfpro], axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the data\n",
    "X, y = df['text'], df['class']\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zengs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess(text):\n",
    "    # replace one or more white-space characters with a space\n",
    "    regex = re.compile(r\"\\s+\")                               \n",
    "    text = regex.sub(' ', text)    \n",
    "    # lower case\n",
    "    text = text.lower()          \n",
    "    # remove digits and punctuation\n",
    "    regex = re.compile(r\"[%s%s]\" % (string.punctuation, string.digits))\n",
    "    text = regex.sub(' ', text)           \n",
    "    # remove stop words\n",
    "    sw = stopwords.words('english')\n",
    "    text = text.split()                                              \n",
    "    text = ' '.join([w for w in text if w not in sw]) \n",
    "    # remove short words\n",
    "    text = ' '.join([w for w in text.split() if len(w) >= 2])\n",
    "    # stem words\n",
    "    text = ' '.join([(PorterStemmer()).stem(w) for w in text.split()]) \n",
    "    # lemmatize\n",
    "    text = ' '.join([(WordNetLemmatizer()).lemmatize(w) for w in text.split()]) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the preprocessing->model pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "clf = Pipeline(steps=[\n",
    "    ('pp', TfidfVectorizer(\n",
    "        preprocessor=preprocess, \n",
    "        use_idf=True, smooth_idf=True, norm='l2',\n",
    "        min_df=1, max_df=1.0, max_features=None, \n",
    "        ngram_range=(1, 1))),\n",
    "    ('mdl', MultinomialNB())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'pp__norm':['l1','l2',None],\n",
    "    'mdl__alpha':[0.01, 0.1, 0.2, 0.5, 1]\n",
    "}\n",
    "gscv = GridSearchCV(clf, param_grid, iid=False, cv=5, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('pp', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2',\n",
      "        preprocessor=<function preproc...se_idf=True, vocabulary=None)), ('mdl', MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# search for best estimator\n",
    "gscv.fit(Xtrain, ytrain)\n",
    "print(gscv.best_estimator_, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444949954504095\n",
      "[[495  56]\n",
      " [  5 543]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94       551\n",
      "           1       0.91      0.99      0.95       548\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1099\n",
      "   macro avg       0.95      0.94      0.94      1099\n",
      "weighted avg       0.95      0.94      0.94      1099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate best_estimator_ on test data\n",
    "ypred = gscv.best_estimator_.predict(Xtest)\n",
    "from sklearn import metrics\n",
    "print (metrics.accuracy_score(ytest, ypred))\n",
    "print (metrics.confusion_matrix(ytest, ypred))\n",
    "print (metrics.classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
